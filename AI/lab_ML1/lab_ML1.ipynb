{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа №1\n",
        "### ***Задача:*** научиться определять пациента с сердечными заболеваниями по его показателям\n",
        "### ***Текущий шаг:*** реализовать линейные моделы классификации(LG, SVM, BN, KNN), проанализировать их результаты"
      ],
      "metadata": {
        "id": "-bDz8_7o--SC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "bGVz_9qpsNSI"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import svm\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def logit(x, w):\n",
        "    return np.dot(x, w)\n",
        "\n",
        "def sigmoid(h):\n",
        "    return 1. / (1. + np.exp(-h))\n",
        "\n",
        "def add_bias_feature(a):\n",
        "    a_extended = np.zeros((a.shape[0],a.shape[1]+1))\n",
        "    a_extended[:,:-1] = a\n",
        "    a_extended[:,-1] = int(1)  \n",
        "    return a_extended"
      ],
      "metadata": {
        "id": "w8-PoW9uAOJ5"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLogisticRegression(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self):\n",
        "        self.w = None\n",
        "    \n",
        "    def fit(self, X, y, max_iter=1000, lr=0.1, activation_function = sigmoid):\n",
        "        \n",
        "        n, k = X.shape\n",
        "        \n",
        "        if self.w is None:\n",
        "            self.w = np.random.randn(k + 1)\n",
        "        \n",
        "        X_train = np.concatenate((np.ones((n, 1)), X), axis=1)\n",
        "        \n",
        "        losses = []\n",
        "        \n",
        "        for iter_num in range(max_iter):\n",
        "            z = activation_function(logit(X_train, self.w))\n",
        "            grad = np.dot(X_train.T, (z - y)) / len(y)\n",
        "\n",
        "            self.w -= grad * lr\n",
        "\n",
        "            losses.append(self.__loss(y, z))\n",
        "        \n",
        "        return losses\n",
        "        \n",
        "    def predict_proba(self, X, activation_function = sigmoid):\n",
        "        n, k = X.shape\n",
        "        X_ = np.concatenate((np.ones((n, 1)), X), axis=1)\n",
        "        return np.array(activation_function(logit(X_, self.w)), dtype = \"int\")\n",
        "\n",
        "    def predict(self, X, threshold=0.5):\n",
        "        return self.predict_proba(X) >= threshold\n",
        "    \n",
        "    def get_weights(self):\n",
        "        return self.w\n",
        "      \n",
        "    def __loss(self, y, p):\n",
        "        p = np.clip(p, 1e-10, 1 - 1e-10)\n",
        "        return np.mean(y * np.log(p) + (1 - y) * np.log(1 - p))"
      ],
      "metadata": {
        "id": "sNMiLji3sZhj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyKNN(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, nn=5):\n",
        "        self.nn = nn\n",
        "\n",
        "    def evklid(self, X):\n",
        "        num_test = X.shape[0]\n",
        "        num_train = self.X.shape[0]\n",
        "\n",
        "        t = np.dot(X, self.X.T)\n",
        "        dists = np.sqrt(-2 * t + np.square(self.X).sum(1) +\n",
        "                        np.matrix(np.square(X).sum(1)).T)\n",
        "        return dists\n",
        "\n",
        "    def fit(self, X, y):  \n",
        "        self.X = X.to_numpy()\n",
        "        self.y = y.to_numpy()\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = X.to_numpy()\n",
        "        dists = self.evklid(X)\n",
        "        preds = np.zeros(dists.shape[0])\n",
        "        for i in range(dists.shape[0]):\n",
        "            labels = self.y[np.argsort(dists[i, :])].flatten()\n",
        "            top_nn_y = labels[:self.nn]\n",
        "            preds[i] = Counter(top_nn_y).most_common(1)[0][0]\n",
        "        return preds"
      ],
      "metadata": {
        "id": "0Cfq7kezAQl_"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MySVM(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, etha=0.01, alpha=0.1, epochs=200):\n",
        "        self._epochs = epochs\n",
        "        self._etha = etha\n",
        "        self._alpha = alpha\n",
        "        self._w = None\n",
        "        self.history_w = []\n",
        "        self.train_errors = None\n",
        "        self.val_errors = None\n",
        "        self.train_loss = None\n",
        "        self.val_loss = None\n",
        "\n",
        "    def fit(self, X_train, Y_train, X_val, Y_val, verbose=False):\n",
        "        X_train, Y_train, X_val, Y_val = X_train.to_numpy(), Y_train.to_numpy(), X_val.to_numpy(), Y_val.to_numpy()\n",
        "\n",
        "\n",
        "        if len(set(Y_train)) != 2 or len(set(Y_val)) != 2:\n",
        "            raise ValueError(\"Number of classes in Y is not equal 2!\")\n",
        "\n",
        "        X_train = add_bias_feature(X_train)\n",
        "        X_val = add_bias_feature(X_val)\n",
        "        self._w = np.random.normal(loc=0, scale=0.05, size=X_train.shape[1])\n",
        "        self.history_w.append(self._w)\n",
        "        train_errors = []\n",
        "        val_errors = []\n",
        "        train_loss_epoch = []\n",
        "        val_loss_epoch = []\n",
        "\n",
        "        for epoch in range(self._epochs): \n",
        "            tr_err = 0\n",
        "            val_err = 0\n",
        "            tr_loss = 0\n",
        "            val_loss = 0\n",
        "            for i,x in enumerate(X_train):\n",
        "                margin = Y_train[i]*np.dot(self._w,X_train[i])\n",
        "                if margin >= 1:\n",
        "                    self._w = self._w - self._etha*self._alpha*self._w/self._epochs\n",
        "                    tr_loss += self.soft_margin_loss(X_train[i],Y_train[i])\n",
        "                else:\n",
        "                    self._w = self._w +\\\n",
        "                    self._etha*(Y_train[i]*X_train[i] - self._alpha*self._w/self._epochs)\n",
        "                    tr_err += 1\n",
        "                    tr_loss += self.soft_margin_loss(X_train[i],Y_train[i])\n",
        "                self.history_w.append(self._w)\n",
        "            for i,x in enumerate(X_val):\n",
        "                val_loss += self.soft_margin_loss(X_val[i], Y_val[i])\n",
        "                val_err += (Y_val[i]*np.dot(self._w,X_val[i])<1).astype(int)\n",
        "            train_errors.append(tr_err)\n",
        "            val_errors.append(val_err)\n",
        "            train_loss_epoch.append(tr_loss)\n",
        "            val_loss_epoch.append(val_loss)\n",
        "        self.history_w = np.array(self.history_w)    \n",
        "        self.train_errors = np.array(train_errors)\n",
        "        self.val_errors = np.array(val_errors)\n",
        "        self.train_loss = np.array(train_loss_epoch)\n",
        "        self.val_loss = np.array(val_loss_epoch)                    \n",
        "\n",
        "    def predict(self, X:np.array) -> np.array:\n",
        "        y_pred = []\n",
        "        X_extended = add_bias_feature(X)\n",
        "        for i in range(len(X_extended)):\n",
        "            y_pred.append(np.sign(np.dot(self._w,X_extended[i])))\n",
        "        return np.array(y_pred)         \n",
        "\n",
        "    def hinge_loss(self, x, y):\n",
        "        return max(0,1 - y*np.dot(x, self._w))\n",
        "\n",
        "    def soft_margin_loss(self, x, y):\n",
        "        return self.hinge_loss(x,y)+self._alpha*np.dot(self._w, self._w)"
      ],
      "metadata": {
        "id": "I639mWg2Apik"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNaive_Bayes(BaseEstimator, ClassifierMixin):\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.classes = np.unique(y_train)\n",
        "        self.n_classes = len(self.classes)\n",
        "        self.prior = np.array(X_train.groupby(y_train).apply(lambda col: len(col)) / len(y_train))\n",
        "        self.mean = np.array(X_train.groupby(y_train).apply(np.mean))\n",
        "        self.var = np.array(X_train.groupby(y_train).apply(np.var))\n",
        "\n",
        "    def gauss_distribution(self, class_idx, x):\n",
        "        mean = self.mean[class_idx]\n",
        "        var = self.var[class_idx]\n",
        "        return np.exp((-1/2) * ((x-mean)**2) / (2 * var)) / np.sqrt(2 * np.pi * var)\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        y_pred = []\n",
        "        for x in np.array(X_test):\n",
        "            posteriors = []\n",
        "            for class_idx in range(self.n_classes):\n",
        "                prior = np.log(self.prior[class_idx])\n",
        "                conditional = np.sum(np.log(self.gauss_distribution(class_idx, x)))\n",
        "                posterior = prior + conditional\n",
        "                posteriors.append(posterior)\n",
        "            y_pred.append(self.classes[np.argmax(posteriors)])\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "tBOkpDjGBUpL"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обработка данных, разбиение выборки"
      ],
      "metadata": {
        "id": "PQoDsH5HDduu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv(\"heart.csv\")\n",
        "names = heart.columns\n",
        "x_train, x_test, y_train, y_test = train_test_split(heart[names[:13]], heart[names[13]])"
      ],
      "metadata": {
        "id": "_o3MC_M9BcPy"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Реализация Pipeline"
      ],
      "metadata": {
        "id": "DK0ArRQIDpUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pipeline(model, x_train, y_train, x_test, y_test):\n",
        "    if isinstance(model, MySVM):\n",
        "        model.fit(x_train, y_train, x_test, y_test)\n",
        "        y_pred = model.predict(x_test)\n",
        "    else:\n",
        "        model.fit(x_train, y_train)\n",
        "        y_pred = model.predict(x_test)\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred), \"\\n\")\n",
        "    print(\"Acuracy score: {}\".format(accuracy_score(y_test, y_pred)))\n",
        "    print(\"Precision score: {}\".format(precision_score(y_test, y_pred)))\n",
        "    print(\"Recall score: {}\".format(recall_score(y_test, y_pred)))    "
      ],
      "metadata": {
        "id": "tC3p7GC8sfjC"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Тестирование своей реализации линейных моделей классификации"
      ],
      "metadata": {
        "id": "P4Ny0xiaDucp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = MyLogisticRegression()\n",
        "pipeline(regressor, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGgvgRkpCzKZ",
        "outputId": "7b9c7ce6-c431-43e8-aeaf-796d5ab1eeda"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[ 7 34]\n",
            " [ 2 33]] \n",
            "\n",
            "Acuracy score: 0.5263157894736842\n",
            "Precision score: 0.4925373134328358\n",
            "Recall score: 0.9428571428571428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = MyKNN()\n",
        "pipeline(knn, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40mfLKNPO9VF",
        "outputId": "176bf365-e2d4-418a-b144-5897e795ecf8"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[27 14]\n",
            " [12 23]] \n",
            "\n",
            "Acuracy score: 0.6578947368421053\n",
            "Precision score: 0.6216216216216216\n",
            "Recall score: 0.6571428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "naive_bayes = MyNaive_Bayes()\n",
        "pipeline(naive_bayes, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJUL9-N0U11X",
        "outputId": "e1794237-7cc3-4bd0-e2e5-543e14c0bd2e"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[33  8]\n",
            " [ 3 32]] \n",
            "\n",
            "Acuracy score: 0.8552631578947368\n",
            "Precision score: 0.8\n",
            "Recall score: 0.9142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm = MySVM()\n",
        "pipeline(svm, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gNjN9rj-rE-",
        "outputId": "8a68b51d-6b71-4caf-ff1d-3c86125f6fa3"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 41]\n",
            " [ 0 35]] \n",
            "\n",
            "Acuracy score: 0.4605263157894737\n",
            "Precision score: 0.4605263157894737\n",
            "Recall score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Тестирование коробочный методов"
      ],
      "metadata": {
        "id": "gAC8kwrsD2YM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "model = LogisticRegression()\n",
        "pipeline(model, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu0_sdlW07Z1",
        "outputId": "7421b276-9268-426a-e296-3e30a0201d1f"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[34  7]\n",
            " [ 4 31]] \n",
            "\n",
            "Acuracy score: 0.8552631578947368\n",
            "Precision score: 0.8157894736842105\n",
            "Recall score: 0.8857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = KNeighborsClassifier(n_neighbors=5)\n",
        "pipeline(model, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMVget591ddJ",
        "outputId": "05158464-12c7-45fa-8de7-7b5d65dd47a7"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[27 14]\n",
            " [12 23]] \n",
            "\n",
            "Acuracy score: 0.6578947368421053\n",
            "Precision score: 0.6216216216216216\n",
            "Recall score: 0.6571428571428571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GaussianNB()\n",
        "pipeline(model, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h81ivR01i9i",
        "outputId": "64b02ca1-9a4c-4b25-9e4b-3b0d75bbc156"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[37  4]\n",
            " [ 6 29]] \n",
            "\n",
            "Acuracy score: 0.868421052631579\n",
            "Precision score: 0.8787878787878788\n",
            "Recall score: 0.8285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = svm.SVC()\n",
        "pipeline(model, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-XwlHZR1q3F",
        "outputId": "5ed57661-68bc-43d8-d452-54baa50c106d"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[17 24]\n",
            " [ 7 28]] \n",
            "\n",
            "Acuracy score: 0.5921052631578947\n",
            "Precision score: 0.5384615384615384\n",
            "Recall score: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Анализ гиперпараметров"
      ],
      "metadata": {
        "id": "YeHxw-EiD-Pc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "model = LogisticRegression()\n",
        "hyperparams = {\n",
        "    \"solver\": ['newton-cg', 'lbfgs'],\n",
        "    \"penalty\": ['l2', 'none'],\n",
        "    \"C\": [100, 10, 1.0, 0.1, 0.01]\n",
        "}\n",
        "grid_search = GridSearchCV(model, hyperparams, cv = 5)\n",
        "grid_result = grid_search.fit(x_train.to_numpy(), y_train.to_numpy())\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAMn0tzN3YCE",
        "outputId": "1250ee79-571a-41e3-ed38-7a466ecdfe95"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.836908 using {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.832560 (0.017987) with: {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.832657 (0.046808) with: {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.832560 (0.017987) with: {'C': 100, 'penalty': 'none', 'solver': 'newton-cg'}\n",
            "0.828213 (0.044359) with: {'C': 100, 'penalty': 'none', 'solver': 'lbfgs'}\n",
            "0.836908 (0.023062) with: {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.828213 (0.044359) with: {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.832560 (0.017987) with: {'C': 10, 'penalty': 'none', 'solver': 'newton-cg'}\n",
            "0.828213 (0.044359) with: {'C': 10, 'penalty': 'none', 'solver': 'lbfgs'}\n",
            "0.836812 (0.030694) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.823768 (0.043617) with: {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.832560 (0.017987) with: {'C': 1.0, 'penalty': 'none', 'solver': 'newton-cg'}\n",
            "0.828213 (0.044359) with: {'C': 1.0, 'penalty': 'none', 'solver': 'lbfgs'}\n",
            "0.832464 (0.023322) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.832367 (0.031149) with: {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.832560 (0.017987) with: {'C': 0.1, 'penalty': 'none', 'solver': 'newton-cg'}\n",
            "0.828213 (0.044359) with: {'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'}\n",
            "0.748792 (0.018765) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
            "0.731401 (0.043566) with: {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
            "0.832560 (0.017987) with: {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\n",
            "0.828213 (0.044359) with: {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "model = LogisticRegression(C = 10, penalty = \"l2\", solver = \"newton-cg\")\n",
        "pipeline(model, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWp0vt3PChSl",
        "outputId": "58dc21a7-0789-4c7b-bc61-7118a0f1f31f"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[35  6]\n",
            " [ 4 31]] \n",
            "\n",
            "Acuracy score: 0.868421052631579\n",
            "Precision score: 0.8378378378378378\n",
            "Recall score: 0.8857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "model = model = KNeighborsClassifier()\n",
        "hyperparams = {\n",
        "    \"leaf_size\": list(range(1, 5)),\n",
        "    \"n_neighbors\": list(range(1, 8)),\n",
        "    \"p\": [1, 2]\n",
        "}\n",
        "grid_search = GridSearchCV(model, hyperparams, cv = 5)\n",
        "grid_result = grid_search.fit(x_train.to_numpy(), y_train.to_numpy())\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFYEcjQe-dcS",
        "outputId": "64990f9e-eaff-4d67-abce-e9023362c496"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best: 0.727150 using {'leaf_size': 1, 'n_neighbors': 6, 'p': 1}\n",
            "0.643188 (0.025005) with: {'leaf_size': 1, 'n_neighbors': 1, 'p': 1}\n",
            "0.621159 (0.025329) with: {'leaf_size': 1, 'n_neighbors': 1, 'p': 2}\n",
            "0.617198 (0.045439) with: {'leaf_size': 1, 'n_neighbors': 2, 'p': 1}\n",
            "0.599614 (0.048535) with: {'leaf_size': 1, 'n_neighbors': 2, 'p': 2}\n",
            "0.696425 (0.054014) with: {'leaf_size': 1, 'n_neighbors': 3, 'p': 1}\n",
            "0.647633 (0.011824) with: {'leaf_size': 1, 'n_neighbors': 3, 'p': 2}\n",
            "0.682995 (0.041764) with: {'leaf_size': 1, 'n_neighbors': 4, 'p': 1}\n",
            "0.660966 (0.043590) with: {'leaf_size': 1, 'n_neighbors': 4, 'p': 2}\n",
            "0.727053 (0.039526) with: {'leaf_size': 1, 'n_neighbors': 5, 'p': 1}\n",
            "0.656425 (0.032512) with: {'leaf_size': 1, 'n_neighbors': 5, 'p': 2}\n",
            "0.727150 (0.041309) with: {'leaf_size': 1, 'n_neighbors': 6, 'p': 1}\n",
            "0.674106 (0.036454) with: {'leaf_size': 1, 'n_neighbors': 6, 'p': 2}\n",
            "0.674589 (0.057854) with: {'leaf_size': 1, 'n_neighbors': 7, 'p': 1}\n",
            "0.652174 (0.047052) with: {'leaf_size': 1, 'n_neighbors': 7, 'p': 2}\n",
            "0.638744 (0.022261) with: {'leaf_size': 2, 'n_neighbors': 1, 'p': 1}\n",
            "0.621159 (0.025329) with: {'leaf_size': 2, 'n_neighbors': 1, 'p': 2}\n",
            "0.617198 (0.045439) with: {'leaf_size': 2, 'n_neighbors': 2, 'p': 1}\n",
            "0.599614 (0.048535) with: {'leaf_size': 2, 'n_neighbors': 2, 'p': 2}\n",
            "0.696425 (0.054014) with: {'leaf_size': 2, 'n_neighbors': 3, 'p': 1}\n",
            "0.647633 (0.011824) with: {'leaf_size': 2, 'n_neighbors': 3, 'p': 2}\n",
            "0.682995 (0.041764) with: {'leaf_size': 2, 'n_neighbors': 4, 'p': 1}\n",
            "0.660966 (0.043590) with: {'leaf_size': 2, 'n_neighbors': 4, 'p': 2}\n",
            "0.727053 (0.039526) with: {'leaf_size': 2, 'n_neighbors': 5, 'p': 1}\n",
            "0.656425 (0.032512) with: {'leaf_size': 2, 'n_neighbors': 5, 'p': 2}\n",
            "0.727150 (0.041309) with: {'leaf_size': 2, 'n_neighbors': 6, 'p': 1}\n",
            "0.674106 (0.036454) with: {'leaf_size': 2, 'n_neighbors': 6, 'p': 2}\n",
            "0.674589 (0.057854) with: {'leaf_size': 2, 'n_neighbors': 7, 'p': 1}\n",
            "0.652174 (0.047052) with: {'leaf_size': 2, 'n_neighbors': 7, 'p': 2}\n",
            "0.638744 (0.022261) with: {'leaf_size': 3, 'n_neighbors': 1, 'p': 1}\n",
            "0.621159 (0.025329) with: {'leaf_size': 3, 'n_neighbors': 1, 'p': 2}\n",
            "0.621546 (0.041089) with: {'leaf_size': 3, 'n_neighbors': 2, 'p': 1}\n",
            "0.599614 (0.048535) with: {'leaf_size': 3, 'n_neighbors': 2, 'p': 2}\n",
            "0.696425 (0.054014) with: {'leaf_size': 3, 'n_neighbors': 3, 'p': 1}\n",
            "0.647633 (0.011824) with: {'leaf_size': 3, 'n_neighbors': 3, 'p': 2}\n",
            "0.687440 (0.040964) with: {'leaf_size': 3, 'n_neighbors': 4, 'p': 1}\n",
            "0.660966 (0.043590) with: {'leaf_size': 3, 'n_neighbors': 4, 'p': 2}\n",
            "0.727053 (0.039526) with: {'leaf_size': 3, 'n_neighbors': 5, 'p': 1}\n",
            "0.656425 (0.032512) with: {'leaf_size': 3, 'n_neighbors': 5, 'p': 2}\n",
            "0.727150 (0.041309) with: {'leaf_size': 3, 'n_neighbors': 6, 'p': 1}\n",
            "0.674106 (0.036454) with: {'leaf_size': 3, 'n_neighbors': 6, 'p': 2}\n",
            "0.674589 (0.057854) with: {'leaf_size': 3, 'n_neighbors': 7, 'p': 1}\n",
            "0.652174 (0.047052) with: {'leaf_size': 3, 'n_neighbors': 7, 'p': 2}\n",
            "0.638744 (0.022261) with: {'leaf_size': 4, 'n_neighbors': 1, 'p': 1}\n",
            "0.621159 (0.025329) with: {'leaf_size': 4, 'n_neighbors': 1, 'p': 2}\n",
            "0.621546 (0.041089) with: {'leaf_size': 4, 'n_neighbors': 2, 'p': 1}\n",
            "0.599614 (0.048535) with: {'leaf_size': 4, 'n_neighbors': 2, 'p': 2}\n",
            "0.696425 (0.054014) with: {'leaf_size': 4, 'n_neighbors': 3, 'p': 1}\n",
            "0.647633 (0.011824) with: {'leaf_size': 4, 'n_neighbors': 3, 'p': 2}\n",
            "0.687440 (0.040964) with: {'leaf_size': 4, 'n_neighbors': 4, 'p': 1}\n",
            "0.660966 (0.043590) with: {'leaf_size': 4, 'n_neighbors': 4, 'p': 2}\n",
            "0.727053 (0.039526) with: {'leaf_size': 4, 'n_neighbors': 5, 'p': 1}\n",
            "0.656425 (0.032512) with: {'leaf_size': 4, 'n_neighbors': 5, 'p': 2}\n",
            "0.727150 (0.041309) with: {'leaf_size': 4, 'n_neighbors': 6, 'p': 1}\n",
            "0.674106 (0.036454) with: {'leaf_size': 4, 'n_neighbors': 6, 'p': 2}\n",
            "0.674589 (0.057854) with: {'leaf_size': 4, 'n_neighbors': 7, 'p': 1}\n",
            "0.652174 (0.047052) with: {'leaf_size': 4, 'n_neighbors': 7, 'p': 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = KNeighborsClassifier(n_neighbors = 6, p = 1, leaf_size = 1)\n",
        "pipeline(model, x_train, y_train, x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgR6_7YqC1i2",
        "outputId": "f92ee6a9-7ae4-4a79-96ae-fe440676ca28"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[32  9]\n",
            " [18 17]] \n",
            "\n",
            "Acuracy score: 0.6447368421052632\n",
            "Precision score: 0.6538461538461539\n",
            "Recall score: 0.4857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Выводы:\n",
        "При решении моей задачи лучше всего себя показал метод наивной байесовской классификации выдав точность на моей задачи 85%+. Он также показал наивысшую точность среди коробочный методов. После анализа изменений гиперпараметров у ЛогРег и КНН я смог убедидиться, что выбор лучших параметров для задачи требует длительного подсчёта и полностью зависит от того, как программист задаёт параметры(они могут улучшить результат как в ЛГ, так и из-за неправильной подачи или неиспользования каких-то важных параметров при анализе, ухудшить его) "
      ],
      "metadata": {
        "id": "CHCynYfIEEoo"
      }
    }
  ]
}